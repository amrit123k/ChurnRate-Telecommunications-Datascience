{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid purple; padding: 10px; margin: 5px\">\n",
    "<b> Svetlana's comment  </b>\n",
    "    \n",
    "\n",
    "Hi, it's Svetlana (https://hub.tripleten.com/u/6dee602c) again.\n",
    "\n",
    "\n",
    "Thank you for submitting such an excellent report! It is well-organized, following a logical structure: what was done, the challenges you faced, the decisions you made, and final results. This makes it easy to follow. You don't need to change anything, because it's great! \n",
    "    \n",
    "Good luck! \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hey this is the solutions report. So lets first go over what steps were performed and what steps were skipped. I have followed all of the data preprocessing as I described: merged dataframes with key column: 'customerID', checked for missing values in the merged dataframe which I found in some of the object datatype features, I filled those with 'unknown.' I checked for duplicates after which I found none. I did however, add a step to the preprocessing task which was feature engineering the 'Tenure' column. It required me to perform some data manipulation in terms of creating a snapshot in time and deleting observations where customers began their service after that snapshot. Although it led to around 13% of the dataset being removed, I believe it is well worth it as Tenure can be a valuable feature in predicting churn rate. It also required me to recalculate TotalCost to align with the snapshot. Also I took the colleagues advice and stuck to one dataframe, df_merged_ohe, which has the categorical features one hot encoded, than working with 2 dataframes for the model training. I believe this will streamline the process and allow me to do a direct comparison between models. I then trained the models: LogisticRegression, RandomForestClassifier, LightGBMClassifier, and CatboostClassifier, as described in the steps. So other than feature engineering Tenure which calculates the length of time customers stayed with the service until the snapshot in time, and sticking to one OHE dataset for model training, I have otherwise followed the steps accordingly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the main difficulties I encountered was proper hyperparameter tuning when training the models. This mainly required some tweaking until I achieved the desired outcomes. I saw a lot of potential in the gradient boosting models so I spent most of my efforts optimizing those models. I tried using GridSearchCV for optimization but it was difficult and time consuming to perform training on a CPU even with all cores working in parallel. Manually tuning the hyperparamers gave me the best results. Also, I initially considered the TotalCost feature to be redundant, as it is a product of Tenure and MonthlyCharges, which the model could implicitly learn. So I removed it and then I noticed I wasn't getting the desired ROC AUC scores from the validation sets. When I added back the TotalCost feature with some minor recalculations to align with the time snapshot, the results were much better so that is very interesting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final model is a tuned CatBoostClassifier, trained using the optimal number of iterations determined through early stopping. It achieved a ROC AUC score of 0.90 on the test set, indicating strong discriminative performance. This suggests the model is highly effective at predicting customer churn and can be confidently implemented by the telecommunications company to support retention strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
